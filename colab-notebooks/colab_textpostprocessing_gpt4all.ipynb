{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonikaBarget/atr-historical-research/blob/main/colab-notebooks/colab_textpostprocessing_gpt4all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "799a853a",
      "metadata": {
        "id": "799a853a"
      },
      "source": [
        "# Named Entity Recognition with OpenAI in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d7fbfd7",
      "metadata": {
        "id": "5d7fbfd7"
      },
      "source": [
        "This is a basic code to test Named Entity Recognition via the OpenAI API, comparing the performance of different models and the efficiency of different prompts.\n",
        "The following models can be tested for Named Entity Recognition:\n",
        "- **text-davinci-003**: Best for high-quality completions.\n",
        "- **gpt-3.5-turbo**: Fast and cost-efficient alternative.\n",
        "- **gpt-4**: More accurate but slower and expensive.\n",
        "- **gpt-4-turbo**: Optimized version of GPT-4, balancing performance and cost.\n",
        "- **ada / curie / babbage**: Lightweight models, suitable for basic tasks.\n",
        "Please choose the smallest model possible when working with AI in the interest of power consumption and environmental concerns. Also, not all tasks may need repeated AI application."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "\n",
        "!pip install nomic gpt4all\n",
        "!mkdir -p /content/gpt4all_models\n",
        "\n",
        "from gpt4all import GPT4All\n",
        "import os\n",
        "import requests\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdLgizcXodz-",
        "outputId": "d4661a8d-6a6d-4e30-fee3-22528d1d2c0c"
      },
      "id": "cdLgizcXodz-",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nomic\n",
            "  Downloading nomic-3.4.1.tar.gz (49 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gpt4all\n",
            "  Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nomic) (8.1.8)\n",
            "Collecting jsonlines (from nomic)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting loguru (from nomic)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from nomic) (13.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nomic) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from nomic) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nomic) (2.2.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from nomic) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nomic) (4.67.1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from nomic) (17.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from nomic) (11.1.0)\n",
            "Requirement already satisfied: pyjwt in /usr/local/lib/python3.11/dist-packages (from nomic) (2.10.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines->nomic) (25.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->nomic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nomic) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nomic) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->nomic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->nomic) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->nomic) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nomic) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nomic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nomic) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nomic) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->nomic) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->nomic) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->nomic) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->nomic) (1.17.0)\n",
            "Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nomic\n",
            "  Building wheel for nomic (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nomic: filename=nomic-3.4.1-py3-none-any.whl size=49942 sha256=4ccfd379236d199eb8b7a7eacacc41611814ff91ce7a432a773978c425e8f8fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/c6/51/4a3cd698715ef6570c9311a5ec5bbf972d41d0c4f3d500e8e3\n",
            "Successfully built nomic\n",
            "Installing collected packages: loguru, jsonlines, gpt4all, nomic\n",
            "Successfully installed gpt4all-2.8.2 jsonlines-4.0.0 loguru-0.7.3 nomic-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/gpt4all_models\n",
        "\n",
        "# Download a verified GPT4All-compatible model from Hugging Face\n",
        "!wget -O /content/gpt4all_models/mistral-7b-instruct.Q4_K_M.gguf \\\n",
        "    https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD7Oqlo8sWNo",
        "outputId": "d201db97-4404-4a3f-eb83-bbbc490b4080"
      },
      "id": "PD7Oqlo8sWNo",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-06 04:31:08--  https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 3.171.171.6, 3.171.171.128, 3.171.171.65, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.171.171.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/46/12/46124cd8d4788fd8e0879883abfc473f247664b987955cc98a08658f7df6b826/14466f9d658bf4a79f96c3f3f22759707c291cac4e62fea625e80c7d32169991?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27mistral-7b-instruct-v0.1.Q4_K_M.gguf%3B+filename%3D%22mistral-7b-instruct-v0.1.Q4_K_M.gguf%22%3B&Expires=1738819868&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczODgxOTg2OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy80Ni8xMi80NjEyNGNkOGQ0Nzg4ZmQ4ZTA4Nzk4ODNhYmZjNDczZjI0NzY2NGI5ODc5NTVjYzk4YTA4NjU4ZjdkZjZiODI2LzE0NDY2ZjlkNjU4YmY0YTc5Zjk2YzNmM2YyMjc1OTcwN2MyOTFjYWM0ZTYyZmVhNjI1ZTgwYzdkMzIxNjk5OTE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=f12gyDMbi0ZqQrb3sw48U6j1PDfkJrPtf-vCxriLl1LAKyZ-nYR56FjHfeY-ZqWwfihuwQ9PW7w5SibAeJ902sLiGdB3CNm5G-OfZKx3IqvgEM2cG18VU120XFeJGMzogZ2qUvVAuNo1yUUpZEf8hz3ZDKeubOJ47XrihP8mSh4LGIe5EtTBiu0D4DaIING9Xx%7E6QGpMYKb2xnsIpNHyleFW8XBUQWA5nqkKe3OfLhduQa0dboAmIJwqOACv86AO5uuo2RdNsEq490MXgg9A1rh22E9KKLvWTY-2h%7EeaJUktjMvtC3u%7EU%7EyJBcAPQyfyYJnXQ1LjrzMRSyU-MqbDGQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-02-06 04:31:08--  https://cdn-lfs.hf.co/repos/46/12/46124cd8d4788fd8e0879883abfc473f247664b987955cc98a08658f7df6b826/14466f9d658bf4a79f96c3f3f22759707c291cac4e62fea625e80c7d32169991?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27mistral-7b-instruct-v0.1.Q4_K_M.gguf%3B+filename%3D%22mistral-7b-instruct-v0.1.Q4_K_M.gguf%22%3B&Expires=1738819868&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczODgxOTg2OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy80Ni8xMi80NjEyNGNkOGQ0Nzg4ZmQ4ZTA4Nzk4ODNhYmZjNDczZjI0NzY2NGI5ODc5NTVjYzk4YTA4NjU4ZjdkZjZiODI2LzE0NDY2ZjlkNjU4YmY0YTc5Zjk2YzNmM2YyMjc1OTcwN2MyOTFjYWM0ZTYyZmVhNjI1ZTgwYzdkMzIxNjk5OTE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=f12gyDMbi0ZqQrb3sw48U6j1PDfkJrPtf-vCxriLl1LAKyZ-nYR56FjHfeY-ZqWwfihuwQ9PW7w5SibAeJ902sLiGdB3CNm5G-OfZKx3IqvgEM2cG18VU120XFeJGMzogZ2qUvVAuNo1yUUpZEf8hz3ZDKeubOJ47XrihP8mSh4LGIe5EtTBiu0D4DaIING9Xx%7E6QGpMYKb2xnsIpNHyleFW8XBUQWA5nqkKe3OfLhduQa0dboAmIJwqOACv86AO5uuo2RdNsEq490MXgg9A1rh22E9KKLvWTY-2h%7EeaJUktjMvtC3u%7EU%7EyJBcAPQyfyYJnXQ1LjrzMRSyU-MqbDGQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.160.78.43, 18.160.78.76, 18.160.78.87, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.160.78.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4368438944 (4.1G) [binary/octet-stream]\n",
            "Saving to: ‘/content/gpt4all_models/mistral-7b-instruct.Q4_K_M.gguf’\n",
            "\n",
            "/content/gpt4all_mo 100%[===================>]   4.07G   188MB/s    in 23s     \n",
            "\n",
            "2025-02-06 04:31:32 (179 MB/s) - ‘/content/gpt4all_models/mistral-7b-instruct.Q4_K_M.gguf’ saved [4368438944/4368438944]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the correct model path\n",
        "model_path = \"/content/gpt4all_models/mistral-7b-instruct.Q4_K_M.gguf\"\n",
        "\n",
        "# Load the GPT4All model\n",
        "model = GPT4All(model_path)"
      ],
      "metadata": {
        "id": "QzM6i0kFuQx1"
      },
      "id": "QzM6i0kFuQx1",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ObxkW6lJaetv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObxkW6lJaetv",
        "outputId": "8f9acf4a-413c-4740-d09d-225fa335718f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up directories\n",
        "output_dir = \"/content/drive/My Drive/Colab Notebooks/OCR_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define the GitHub raw file URL (replace with actual URL)\n",
        "github_raw_url = \"https://raw.githubusercontent.com/MonikaBarget/atr-historical-research/refs/heads/main/sample_data_txt/DeutscheKolonialZeitung.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following section is necessary because models typically only allow the processing of a limited amount of text at a time.\n",
        "* Mistral-7B\t= 4096 tokens\n",
        "* LLaMA-2 7B\t= 4096 tokens\n",
        "* GPT4All Default\t= 2048 tokens\n",
        "* Smaller Models\t= 1024 tokens\n",
        "\n",
        "Please keep in mind that the message with instructions you give to the model counts towards your prompt, as well as the text you ingest. AI APIs for which you pay will allow greater data sets to be processed when you subscribe."
      ],
      "metadata": {
        "id": "Fj0XggMe1VX6"
      },
      "id": "Fj0XggMe1VX6"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "xvNIhxD7dpcD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvNIhxD7dpcD",
        "outputId": "2951b675-24e9-4e12-dbc9-d74bab5052f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truncating input text from 1201 tokens to 700 tokens.\n",
            "Downloaded and truncated OCR text from GitHub.\n"
          ]
        }
      ],
      "source": [
        "# Function to reduce input text to fit within model's token limit\n",
        "def truncate_text(text, max_tokens):\n",
        "    words = text.split()  # Split text into words\n",
        "    if len(words) > max_tokens:\n",
        "        print(f\"Truncating input text from {len(words)} tokens to {max_tokens} tokens.\")\n",
        "        words = words[:max_tokens] # first words # [-max_tokens:] = only the last words\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Download the text file from GitHub\n",
        "response = requests.get(github_raw_url)\n",
        "\n",
        "# Check if the file exists and apply text limitation\n",
        "if response.status_code == 200:\n",
        "    input_text = response.text\n",
        "    input_text = truncate_text(input_text, max_tokens=700)  # Limit text size\n",
        "    print(f\"Downloaded and truncated OCR text from GitHub.\")\n",
        "else:\n",
        "    print(f\"Failed to download file. HTTP Status Code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USE CASE 1: TEXT CORRECTION\n",
        "# warning: Python API access is slow and this code will take around 15 minutes to complete\n",
        "\n",
        "# Define output file\n",
        "output_file = os.path.join(output_dir, \"corrected_ocr_text.txt\")\n",
        "\n",
        "# Function to correct spelling mistakes\n",
        "def process_text(input_text, output_file):\n",
        "    prompt = f\"Correct spelling mistakes and falsely identified characters in the following OCR-generated text:\\n{input_text}\"\n",
        "    corrected_text = model.generate(prompt)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(corrected_text)\n",
        "        return corrected_text\n",
        "\n",
        "corrected_text = process_text(input_text, output_file)\n",
        "print(corrected_text)\n",
        "print(f\"Corrected text written to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5kHP5lXfcl3",
        "outputId": "7429d9c2-1ab4-4146-eca6-c799a78b2215"
      },
      "id": "u5kHP5lXfcl3",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " beginnt und die deutschen Kolonien werden zur Mutterlandschaft der zukünftigen Weltmächte geworden sein.\n",
            "#9 ################################################ Deutsche Kolonialzeitung. Organ der Deutſchen Kolonialgesellschaft. Die Deutsche Kolonialzeitung erscheint vierwöchentlich. - Redakteur: Gustav Meinecke. - Alle Sendungen für die Redaktion und Expedition dieses Blattes sind zu richten an die Adreffe: Deutsche kolonialgeſellschaft, Berlin W., Linkſtraße 25. Nr. 1592 der Postzeitungsliste - oder im Buchhandel) jährlich Bezugspreis in Deutſchland und Österreich-Ungarn (durch die Post Als Jahresbeitrag find in Deuutschland und 8 Mart, im Auslande j\n",
            "Corrected text written to /content/drive/My Drive/Colab Notebooks/OCR_outputs/corrected_ocr_text.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USE CASE 2: IDENTIFY NAMED ENTITIES\n",
        "# warning: Python API access is slow and this code will take around 15 minutes to complete\n",
        "\n",
        "# Define output file\n",
        "output_file = os.path.join(output_dir, \"tagged_ocr_text.txt\")\n",
        "\n",
        "# Function to identify named entities using GPT4All\n",
        "def tag_named_entities(corrected_text, output_file):\n",
        "    prompt = f\"Mark all named entities in the following text, marking possible person names and place names with <person> and <place> XML tag:\\n\\n{corrected_text}\"\n",
        "    tagged_text = model.generate(prompt)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(tagged_text)\n",
        "        return tagged_text\n",
        "\n",
        "tagged_text = tag_named_entities(corrected_text, output_file)\n",
        "print(tagged_text)\n",
        "print(f\"Tagged text with named entities written to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4WGjYbmomhH",
        "outputId": "7d95dc61-3907-4982-ca5c-af5a99c5fb22"
      },
      "id": "m4WGjYbmomhH",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eder Zeitung durch den Verleger.\n",
            "#10 ################################################ Die Deutsche Kolonialzeitung ist ein Blatt der deutschen Kolonialgesellschaft, welche die deutsche Weltmacht mit dem Namen \"Deutsches Reich\" gegründet hat. - Redakteur: Gustav Meinecke. - Alle Sendungen für die Redaktion und Expedition dieses Blattes sind zu richten an die Adreffe: Deutsche kolonialgeſellschaft, Berlin W., Linkſtraße 25. Nr. 1592 der Postzeitungsliste - oder im Buchhandel) jährlich Bezugspreis in Deuutschland und Österreich-Ungarn (durch die Post Als Jahresbeitrag find in Deuutschland und 8 Mart, im Auslande jeder Zeitung durch den Verleger.\n",
            "#11 ###################################\n",
            "Tagged text with XML entities written to /content/drive/My Drive/Colab Notebooks/OCR_outputs/tagged_ocr_text.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}